<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
        "http://www.w3c.org/TR/1999/REC-html401-19991224/loose.dtd">
<html xml:lang="en" xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
    <title>Multi-view Depth Estimation using Epipolar Spatio-Temporal Network</title>
    <meta http-equiv="Content-Type" content="text/html; charset=windows-1252">

    <meta property="og:image" content=""/>
    <meta property="og:title" content="Multi-view Depth Estimation using Epipolar Spatio-Temporal Network"/>


    <script>
        (function (i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r;
            i[r] = i[r] || function () {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date();
            a = s.createElement(o),
                m = s.getElementsByTagName(o)[0];
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m)
        })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

        ga('create', 'UA-53682931-1', 'auto');
        ga('send', 'pageview');

    </script>

    <script type="text/javascript">
        // redefining default features
        var _POPUP_FEATURES = 'width=500,height=300,resizable=1,scrollbars=1,titlebar=1,status=1';
    </script>
    <link media="all" href="glab.css" type="text/css" rel="StyleSheet">
    <style type="text/css" media="all">
        IMG {
            PADDING-RIGHT: 0px;
            PADDING-LEFT: 0px;
            FLOAT: right;
            PADDING-BOTTOM: 0px;
            PADDING-TOP: 0px
        }

        #primarycontent {
            MARGIN-LEFT: auto;;
            WIDTH: expression(document.body.clientWidth >
1150? "1150px": "auto" );
            MARGIN-RIGHT: auto;
            TEXT-ALIGN: left;
            max-width: 1150px
        }

        BODY {
            TEXT-ALIGN: center
        }
    </style>

<body>

<div id="primarycontent">
    <center><h1 style="font-size:36px">Multi-view Depth Estimation using Epipolar Spatio-Temporal Network</h1></center>

    <center><h2>
        <a href="mailto:xxlong@hku.hk">Xiaoxiao Long<sup>1</sup>&nbsp;&nbsp;
            <a href="https://lingjie0206.github.io/">Lingjie Liu</a><sup>2</sup>&nbsp;&nbsp;
            Wei li<sup>3</sup>&nbsp;&nbsp;
            <a href="http://people.mpi-inf.mpg.de/~theobalt/">Christian Theobalt</a><sup>2</sup>&nbsp;&nbsp;
            <a href="https://i.cs.hku.hk/~wenping/">Wenping Wang</a><sup>1</sup>&nbsp;&nbsp;</h2></center>

    <center><h2><sup>1</sup>The University of Hong Kong&nbsp;&nbsp;<sup>2</sup>Max Planck Institute for Informatics&nbsp;&nbsp;<sup>3</sup>Inceptio&nbsp;
    </h2></center>

    <center><h2>arXiv 2020</h2></center>
    <br>
    <hr/>
    <br>
    <center><a href="images/teaser.png">
        <img style="PADDING-LEFT: 220px; PADDING-RIGHT: 220px;" src="images/teaser.png" width="720"> </a></center>

    <h1>Abstract</h1>
    <div style="font-size:14px; text-align:justify;"><p>We present a novel method for multi-view depth estimation from a
        single video, which is a critical task in various applications, such as perception, reconstruction and robot
        navigation. Although previous learning-based methods have demonstrated compelling results, most works estimate
        depth maps of individual video frames independently, without taking into consideration the strong geometric and
        temporal coherence among the frames. Moreover, current state-of-the-art (SOTA) models mostly adopt a fully 3D
        convolution network for cost regularization and therefore require high computational cost, thus limiting their
        deployment in real-world applications. Our method achieves temporally coherent depth estimation results by using
        a novel Epipolar Spatio-Temporal (EST) transformer to explicitly associate geometric and temporal correlation
        with multiple estimated depth maps. Furthermore, to reduce the computational cost, inspired by recent
        Mixture-of-Experts models, we design a compact hybrid network consisting of a 2D context-aware network and a 3D
        matching network which learn 2D context information and 3D disparity cues separately. Extensive experiments
        demonstrate that our method achieves higher accuracy in depth estimation and significant speedup than the SOTA
        methods.
    </p></div>
    <table align="left" border="0" cellspacing="0" cellpadding="0">
        <tr>
            <td align="left" valign="middle">

                <a href="https://arxiv.org/pdf/2004.00845.pdf">
                    <image width="130" height="130" src="images/paper_thumbnail.png">
                </a>

            </td>
            <td align="left" valign="middle">

                <a href="https://github.com/xxlong0/ESTDepth">
                    <image width="130" height="130" src="images/data_ico.jpg">
                </a>

            </td>
        </tr>
        <tr>
            <td align="middle" valign="middle">
                <a href="https://arxiv.org/pdf/2004.00845.pdf" width="100" height="100"
                   style="font-size: 18px">Paper</a>
            </td>
            <td align="middle" valign="middle">
                <a href="https://github.com/xxlong0/ESTDepth" width="100" height="100" style="font-size: 18px">Code</a>
            </td>
        </tr>

    </table>
    <br>

    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <br>
    <hr/>


    <h1>Overview</h1>
    <img style="PADDING-LEFT: 80px; PADDING-RIGHT: 80px;" src="images/pipeline.png" width="1000"> </a></center>
    <div style="font-size:14px; text-align:justify;"><p> Overview of our method. In the training stage, our method takes
        a clip of video with five frames as input to estimate the depth maps of the middle three target frames. For each
        target image with its source images, we first extract learned feature maps by a shallow feature extractor.
        Subsequent plane-sweeping warping is applied to the feature maps to construct raw matching volume, and it is
        further regularized by MatchNet to obtain a regularized matching volume. In parallel, we utilize
        ContextNet to learn 2D context information from the target image, and concatenate context volume and
        matching volume together to get one hybrid volume. The Epipolar Spatio-Temporal (EST) transformer is applied on
        all obtained hybrid volumes to associate temporal coherence with them. Finally, we extract initial depth maps
        from the transformed volumes and further refine the initial depth maps by RefineNet.</p></div>


    <!--<h2>Citation</h2>
    <p>
    <a href="Bibtex.txt">Bibtex</a>

    </p>-->

    <hr/>
    <h1>Video</h1>
    <table align="center" border="0" cellspacing="0" cellpadding="0">
        <tr>
            <td align="center" valign="middle">

                <iframe width="560" height="315" src="https://www.youtube.com/embed/FuMi_TZA1X0" frameborder="0"
                        allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
                        allowfullscreen></iframe>
            </td>
        </tr>


    </table>
    <p>&nbsp;</p>
    <hr/>


    <!--<h1>Acknowledgement</h1>-->
    <!--<p>We thank the reviewers for the suggestions, Changjian Li, Guodong Wei, Yumeng Liu for the-->
    <!--valuable discussions.</p>-->
    <!--<br>-->
    <!--<br>-->
    <!--<br>-->
    <!--<br>-->
    <!--<h2>Citation</h2>
    <p></p>-->

    <div style="display:none">
        <!-- GoStats JavaScript Based Code -->
        <script type="text/javascript" src="http://gostats.com/js/counter.js"></script>
        <script type="text/javascript">_gos = 'c3.gostats.com';
        _goa = 390583;
        _got = 4;
        _goi = 1;
        _goz = 0;
        _god = 'hits';
        _gol = 'web page statistics from GoStats';
        _GoStatsRun();</script>
        <noscript><a target="_blank" title="web page statistics from GoStats"
                     href="http://gostats.com"><img alt="web page statistics from GoStats"
                                                    src="http://c3.gostats.com/bin/count/a_390583/t_4/i_1/z_0/show_hits/counter.png"
                                                    style="border-width:0"/></a></noscript>
    </div>
    <!-- End GoStats JavaScript Based Code -->
</body>
</html>
